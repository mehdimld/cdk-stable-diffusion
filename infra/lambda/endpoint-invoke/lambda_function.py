from urllib.parse import unquote_plus
import json
import boto3
from botocore.config import Config
from sagemaker.session import Session
from sagemaker.huggingface.model import HuggingFacePredictor
import time
import re

# Endpoint name used to get the model
import os

ENDPOINT_NAME = os.environ['endpoint_name']
# Body Template to generate the html file
BODY_TEMPLATE = '<html><head></head><body><img src="data:image/png;base64,IMAGE"/><br><h3>PROMPT</h3></body></html>'

# Config of the sagemaker session
config = Config(read_timeout=30, retries={
                "max_attempts": 0}, region_name='eu-west-3')
sagemaker_runtime_client = boto3.client("sagemaker-runtime", config=config)
sagemaker_session = Session(sagemaker_runtime_client=sagemaker_runtime_client)
# Creating a HuggingFacePredictor based on the model deployed in the Endpoint
predictor = HuggingFacePredictor(endpoint_name=ENDPOINT_NAME)
# Init of the s3 clients and resources
# TODO: Check if theses two are needed. s3_client has been added to use the put method as implemented in the handler.
s3 = boto3.resource('s3')
s3_client = boto3.client("s3")


def inference(prompt: str) -> dict:
    """ The inference function takes as input a string and return 
    the image generated by the stable diffusion algorithm. res is in fact a dict : 
    - res[data] --> image encoded
    - res['prompt'] --> the text used to make the prediction
    """
    data = {"prompt": prompt} if prompt else {}

    print(f"Starting inference with {data}")
    res = predictor.predict(data=data)
    print("Inference completed")

    return res


def lambda_handler(event, context):
    print("Getting input data")
    input_bucket = event['Records'][0]['s3']['bucket']['name']
    input_key = unquote_plus(
        event['Records'][0]['s3']['object']['key'], encoding='utf-8')
    print(input_key, input_bucket)
    if input_key.split('.')[1] == 'json': 
        obj = s3.Object(input_bucket, input_key)
        data = obj.get()['Body']
        text_input = json.loads(data.read())[
            'results']['transcripts'][0]['transcript']
        res = inference(text_input)
        output_key = re.sub('[^A-Za-z0-9]+', '', res["prompt"]
                            )[:10] + str(time.time()) + ".html"
        output_body = BODY_TEMPLATE.replace("IMAGE", res["data"]).replace(
            "PROMPT", res["prompt"])
        s3_client.put_object(
            Bucket='stable-diffusion-output-bucket',
            Key=output_key,
            Body=output_body,
            CacheControl="max-age=0,no-cache,no-store,must-revalidate",
            ContentType="text/html")

    return 200
